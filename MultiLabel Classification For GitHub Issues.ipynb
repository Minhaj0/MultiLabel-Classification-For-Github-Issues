{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "480496f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Numbers of issues: 36816\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "read_file=open(\"data.txt\",'r')\n",
    "git_issues_data=read_file.read()\n",
    "git_issues_data=json.loads(git_issues_data)\n",
    "print(\"Total Numbers of issues:\",len(git_issues_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e3aeae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Numbers of issues: 36816\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "for i in range(len(git_issues_data)):\n",
    "    text=''\n",
    "    if 'body' in git_issues_data[i] and git_issues_data[i]['body'] is not None:\n",
    "        git_issues_data[i]['body'] = ' '.join([word for word in git_issues_data[i]['body'].split() if word not in STOPWORDS])\n",
    "    else:\n",
    "        git_issues_data[i]['body'] = ''\n",
    "print(\"Total Numbers of issues:\",len(git_issues_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "867fb917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18561\n"
     ]
    }
   ],
   "source": [
    "dataset_for_training_model=[]\n",
    "all_labels=[]\n",
    "for item in git_issues_data:\n",
    "    labels=[]\n",
    "    labels.extend([\n",
    "        obj['name']\n",
    "        for obj in item['labels']\n",
    "    ])\n",
    "    all_labels.extend([*labels])\n",
    "    if len(labels) > 0:\n",
    "        dataset_for_training_model.extend([{\n",
    "        'id':item['id'],\n",
    "        'body':item['body'],\n",
    "        'url':item['url'],\n",
    "        'title':item['title'],\n",
    "        'language':item['language'],\n",
    "        'labels':labels\n",
    "    }])\n",
    "print(len(dataset_for_training_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "609e974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                body  \\\n",
      "0  Bumps [Selenium.WebDriver.ChromeDriver](https:...   \n",
      "1  Bumps [Microsoft.SourceLink.GitHub](https://gi...   \n",
      "2  ### Describe feature Based available HTML elem...   \n",
      "3  ### Describe feature Based available HTML elem...   \n",
      "4  ### Describe feature Simply, upgrading current...   \n",
      "\n",
      "                                               title language  \\\n",
      "0  Bump Selenium.WebDriver.ChromeDriver from 119....     .NET   \n",
      "1  Bump Microsoft.SourceLink.GitHub from 1.1.1 to...     .NET   \n",
      "2  [Feature] Page object generation for Vue.js files     .NET   \n",
      "3    [Feature] Page object generation for HTML files     .NET   \n",
      "4                    [Feature] Upgrade to Selenium 4     .NET   \n",
      "\n",
      "                                         labels  \n",
      "0                          [dependencies, .NET]  \n",
      "1                          [dependencies, .NET]  \n",
      "2  [enhancement, good first issue, help wanted]  \n",
      "3  [enhancement, good first issue, help wanted]  \n",
      "4              [enhancement, help wanted, hold]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(dataset_for_training_model)\n",
    "df['body'].replace('', np.nan, inplace=True)\n",
    "df = df.drop(['id', 'url'], axis =1)\n",
    "df.dropna(subset=['body'], inplace=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e608fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "df['text'] = df['body'] + ' ' + df['title'] + ' ' + df['language']\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(df['text'])\n",
    "y = df['labels'].str.get_dummies(sep=',')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "multi_target_forest = MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "multi_target_forest.fit(X_train, y_train)\n",
    "y_pred = multi_target_forest.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdeff21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
